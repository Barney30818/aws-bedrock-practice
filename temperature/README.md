# Introduction

**Temperature** is an inference parameter that influences the variabilty of the responses generated by a foundation model.

You can think of temperature as a way to control the creativity & variability of the model. A temperature of 0 means no variability - the current version* of the model will return a consistent response to the same prompt. The higher the temperature, the more variation in responses can be expected. In creative scenarios like content creation, a higher temperature can be helpful. In business process scenarios & code generation, a temperature of zero may be best.

------------

Build the function: `get_text_response(input_content, temperature)` to call Bedrock with the appropriate inference parameters for the model.

Here we are instantiating the LangChain Bedrock client, setting the prompt, and setting the temperature.

# Run the script

- Run the script from the terminal, setting the temperature to 0.0.

`python temperature.py "Write a haiku about a long journey:" 0.0`

- Try to run the script from the terminal, this time setting the temperature to 1.0.

`python temperature.py "Write a haiku about a long journey:" 1.0`